name: Advanced Proxy Collector

permissions:
  contents: write

on:
  schedule:
    - cron: '0 * * * *' # Ø§Ø¬Ø±Ø§ Ø³Ø± Ù‡Ø± Ø³Ø§Ø¹Øª
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Dependencies
      run: |
        pip install requests

    - name: Create and Run Script
      run: |
        # Ù†ÙˆØ´ØªÙ† Ú©Ø¯ Ù¾Ø§ÛŒØªÙˆÙ† Ø¯Ø§Ø®Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ Ù…Ø¬Ø²Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Ù†Ú¯Ø§Ø±Ø´ÛŒ
        cat << 'EOF' > collector.py
        import requests
        import base64
        import json
        import re
        import socket
        import concurrent.futures
        from urllib.parse import urlparse

        # --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
        SOURCES = [
            'https://chat.tawana.online/sub/tawanaproxy.txt',
           # 'https://raw.githubusercontent.com/mahdibland/V2RayAggregator/master/EternityAirports_sub.txt',
           #  'https://raw.githubusercontent.com/ebrasha/free-v2ray-public-list/main/all_extracted_configs.txt',
        ]
        OUTPUT_FILE = 'sub.txt'
        TIMEOUT = 2
        MAX_WORKERS = 50

        def get_flag(country_code):
            if not country_code: return 'ğŸš©'
            return chr(127397 + ord(country_code[0])) + chr(127397 + ord(country_code[1]))

        def parse_config(config):
            try:
                if config.startswith('vmess://'):
                    b64 = config[8:]
                    padding = len(b64) % 4
                    if padding: b64 += '=' * (4 - padding)
                    decoded_str = base64.b64decode(b64).decode('utf-8', errors='ignore')
                    data = json.loads(decoded_str)
                    return {'type': 'vmess', 'ip': data['add'], 'port': int(data['port']), 'data': data}
                
                elif config.startswith('vless://') or config.startswith('trojan://'):
                    match = re.search(r'://(?:.*@)?([\w\.-]+):(\d+)', config)
                    if match:
                        return {'type': config.split(':')[0], 'ip': match.group(1), 'port': int(match.group(2)), 'raw': config}
            except:
                pass
            return None

        def check_connection(proxy_info):
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(TIMEOUT)
                result = sock.connect_ex((proxy_info['ip'], proxy_info['port']))
                sock.close()
                return result == 0
            except:
                return False

        # --- Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
        print('Downloading sources...')
        raw_content = ''
        for url in SOURCES:
            try:
                resp = requests.get(url, timeout=10)
                if resp.status_code == 200:
                    content = resp.text.strip()
                    # Ø¯ÛŒÚ©Ø¯ Ú©Ø±Ø¯Ù† Ø§Ú¯Ø± Ú©Ù„ ÙØ§ÛŒÙ„ Ø¨ÛŒØ³Û¶Û´ Ø¨Ø§Ø´Ø¯
                    try:
                        if not '://' in content[:20]:
                            content = base64.b64decode(content).decode('utf-8', errors='ignore')
                    except:
                        pass
                    raw_content += content + '\n'
            except Exception as e:
                print(f'Error downloading {url}: {e}')

        config_lines = raw_content.splitlines()
        parsed_list = []
        unique_ips = set()

        for line in config_lines:
            line = line.strip()
            if not line: continue
            info = parse_config(line)
            if info:
                # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ IP
                if info['ip'] not in unique_ips:
                    parsed_list.append(info)
                    unique_ips.add(info['ip'])

        print(f'Total Configs Found: {len(parsed_list)}')

        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø´ÙˆØ±
        print('Getting GeoIP info...')
        ip_country_map = {}
        ips = list(unique_ips)
        for i in range(0, len(ips), 100):
            batch = ips[i:i+100]
            try:
                resp = requests.post('http://ip-api.com/batch', json=[{'query': ip, 'fields': 'query,country,countryCode'} for ip in batch], timeout=15)
                for item in resp.json():
                    if 'country' in item:
                        ip_country_map[item['query']] = {'name': item['country'], 'code': item['countryCode']}
            except Exception as e:
                print(f'GeoIP Error: {e}')

        # ØªØ³Øª Ùˆ ØªØºÛŒÛŒØ± Ù†Ø§Ù…
        print('Checking health and renaming...')
        final_configs = []

        def process_single(info):
            if check_connection(info):
                country_data = ip_country_map.get(info['ip'], {'name': 'Unknown', 'code': 'UN'})
                flag = get_flag(country_data['code'])
                new_name = f"smkn-{country_data['name']}-{flag}"
                
                if info['type'] == 'vmess':
                    info['data']['ps'] = new_name
                    new_json = json.dumps(info['data'])
                    new_str = 'vmess://' + base64.b64encode(new_json.encode('utf-8')).decode('utf-8')
                    return new_str
                elif info['type'] in ['vless', 'trojan']:
                    base_uri = info['raw'].split('#')[0]
                    return f"{base_uri}#{new_name}"
            return None

        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            results = executor.map(process_single, parsed_list)
            for res in results:
                if res:
                    final_configs.append(res)

        print(f'Alive configs: {len(final_configs)}')
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write('\n'.join(final_configs))
        EOF
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡
        python3 collector.py

    - name: Commit and Push
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        git add sub.txt
        git commit -m "Updated proxies" || echo "No changes to commit"
        git push
